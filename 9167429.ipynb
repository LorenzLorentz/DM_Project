{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 用户购买预测baseline\n",
    "$\\color{red}{Tips：该部分主要为介绍思路和基线修改指南，实战部分在后半部分单独列出}$\n",
    "## 赛题介绍\n",
    "智能营销工具可以帮助商家预测用户购买的行为，本次比赛提供了一份品牌商家的历史订单数据，参赛选手需构建一个预测模型，预估用户人群在规定时间内产生购买行为的概率。\n",
    "该模型可应用于各种电商数据分析，以及百度电商开放平台， 不仅可以帮助商家基于平台流量，进行商品售卖、支付，还可以通过MarTech技术更精准地锁定核心用户，对用户的购买行为进行预测。\n",
    "\n",
    "- $\\color{red}{特别注意：数据进行了模拟生成，对某些特征含义进行了隐藏，并进行了脱敏处理}$\n",
    "\n",
    "- $\\color{red}{特别注意：本次比赛需要选手使用飞桨PaddlePaddle1.7以及以上版本参赛}$\n",
    "\n",
    "[点击跳转至赛题页面](https://aistudio.baidu.com/aistudio/competition/detail/51)\n",
    "\n",
    "## 基线介绍\n",
    "### 运行方式\n",
    "\n",
    "本次基线基于飞桨PaddlePaddle1.8版本，若本地运行则可能需要额外安装jupyter notebook环境、pandas模块等。\n",
    "AI Studio上运行建议使用32G内存的高级版，本地运行同样建议配置较大的内存空间。\n",
    "\n",
    "#### AI Studio (Notebook)运行\n",
    "\n",
    "依次运行下方的cell即可，若运行时修改了cell，推荐在右上角重启执行器后再以此运行，避免因内存未清空而产生报错。\n",
    "\n",
    "#### 本地运行\n",
    "\n",
    "fork本项目后点击右上角的“文件”——“导出Notebook为ipynb”，下载到本地后在`jupyter notebook`环境即可开始训练，生成的推理结果文件为`submission.csv`。\n",
    "\n",
    "### 设计思想\n",
    "\n",
    "#### 执行流程\n",
    "\n",
    "1. 配置预处理数据方案(选手可以自行设计，默认提供用于时间滑窗特征工程和归一化两种方案)\n",
    "2. 检查数据是否可以正确读取（可省略，若选手自行修改了数据预处理部分，务必检查能否读取后再进行下一步操作）\n",
    "3. 开始训练\n",
    "4. 执行预测并产生结果文件\n",
    "\n",
    "#### 技术方案\n",
    "在本次赛题中，虽然赛题是一个二分类任务（用户购买、未购买），但从赛题数据看，属于比较典型的时间序列数据，也可以参照以往的线性回归任务的做法处理。 \n",
    "接下来将介绍技术方案中的一些细节问题以及method流程。\n",
    "\n",
    "##### label设计\n",
    "本次赛题反映了一个客观事实——在真实场景应用机器学习/深度学习技术时，通常是没有已经整理好的训练集、验证集、测试集，需要自己设计。\n",
    "\n",
    "比如赛题中提到，在比赛任务是预测下个月用户是否购买，下个月是哪个月？我们不妨设想自己是个业务经理，现在领导说做个模型，预测下个月你手上的客户是否会流失。所以在这类题目中，下个月就是提供的数据集截止日期之后的一个月。当然，如果比赛要求预测未来7天、未来15天的销售情况，道理也是一样的。\n",
    "\n",
    "在此类比赛的解决方案中，通常会有个时间滑窗的概念。比如按月进行时间滑窗，本题中数据到2013.8.31，默认提供的数据集划分设计如下（选手也可以自行设计数据集的划分）：\n",
    "- 训练集：用2013年4-6月的数据预测用户在7月是否购买\n",
    "- 验证集：用2013年5-7月的数据预测用户在8月是否购买\n",
    "- 测试集：用2013年6-8月的数据预测用户在9月是否购买（其实就是预测的目标）\n",
    "\n",
    "```python\n",
    "# 这是一个时间滑窗函数，获得dt之前minus天以来periods的dataframe，以便进一步计算\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "```\n",
    "\n",
    "##### 时间滑窗特征构建\n",
    "> 注：更详细的时间滑窗特征工程的方法请参考[用户购买预测时间滑窗特征构建](https://aistudio.baidu.com/aistudio/projectdetail/276829)，本项目做了大幅缩减。\n",
    "\n",
    "时间滑窗在业务应用上被称为RFM模型，RFM模型最早是用来衡量客户价值和客户创利能力。理解RFM框架的思想是构造统计类特征的基础，其含义为：\n",
    "- R（Recency）：客户最近一次交易消费时间的间隔。R值越大，表示客户交易发生的日期越久，反之则表示客户交易发生的日期越近。\n",
    "- F（Frequency）：客户在最近一段时间内交易消费的次数。F值越大，表示客户交易越频繁，反之则表示客户交易不够活跃。\n",
    "- M（Monetary）：客户在最近一段时间内交易消费的金额。M值越大，表示客户价值越高，反之则表示客户价值越低。\n",
    "\n",
    "也就是说，时间滑窗特征本身是与业务紧密联系的，而在这类时间序列数据的比赛中，滑动时间窗口内的统计指标可以更加丰富，统计值一般会有最大值、最小值、均值、标准差、中位数、极差等。\n",
    "\n",
    "```python\n",
    "# 要计算统计指标特征的时间窗口\n",
    "for i in [14,30,60,91]:\n",
    "\ttmp = get_timespan(df_payment, t2018, i, i)\n",
    "   # 削去峰值的均值特征\n",
    "   X['mean_%s_decay' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "   # 中位数特征，在本赛题中基本不适用\n",
    "   # X['median_%s' % i] = tmp.median(axis=1).values\n",
    "   # 最小值特征，在本赛题中基本不适用\n",
    "   # X['min_%s' % i] = tmp_1.min(axis=1).values\n",
    "   # 最大值特征\n",
    "   X['max_%s' % i] = tmp.max(axis=1).values\n",
    "   # 标准差特征\n",
    "   # X['std_%s' % i] = tmp_1.std(axis=1).values\n",
    "   # 求和特征\n",
    "   X['sum_%s' % i] = tmp.sum(axis=1).values\n",
    "```\n",
    "##### 深度学习模型搭建\n",
    "参考[使用飞桨重写房价预测模型](https://aistudio.baidu.com/aistudio/projectdetail/366426)和[Martech_track1_beta](https://aistudio.baidu.com/aistudio/projectdetail/510779)搭建三层深度神经网络。需要注意的是，由于神经网络对缺失值和稀疏数据敏感，对送入神经网络的特征需要做筛选。另外，选择哪种神经网络结构效果更好，需要参赛选手进一步探索。\n",
    "```python\n",
    "# 构建多层神经网络\n",
    "class Regressor(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(Regressor, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        # 定义三层全连接层，输入维度是最终选取的特征数量，输出维度是1，激活函数为relu\n",
    "        self.fc1 = Linear(input_dim=41, output_dim=128, act='relu') # 输入层，input dim 为数据维度大小\n",
    "        self.fc2 = Linear(input_dim=128, output_dim=128, act='relu')\n",
    "        self.fc3 = Linear(input_dim=128, output_dim=1, act='sigmoid')\n",
    "    # 网络的前向计算函数\n",
    "    def forward(self, inputs):\n",
    "        fc1 = self.fc1(inputs)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        x = self.fc3(fc2)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据预处理 - 数据集划分与特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzlorentz/anaconda/anaconda3/envs/dm/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  #\n",
    "import pandas as pd  #\n",
    "from datetime import datetime, date, timedelta\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "# from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV,Ridge,Lasso,ElasticNet\n",
    "# from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor,RandomForestClassifier\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# from sklearn.svm import SVR, LinearSVC\n",
    "# from sklearn.pipeline import make_pipeline,Pipeline\n",
    "# from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler,MinMaxScaler\n",
    "# from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from itertools import product\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import gc\n",
    "from datetime import date, timedelta\n",
    "import paddle\n",
    "# import paddle.fluid as fluid\n",
    "# import paddle.fluid.dygraph as dygraph\n",
    "# from paddle.fluid.dygraph import Linear\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = 'Data/'\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "# train = pd.read_csv('./data/data19383/train.csv', usecols=[2, 3, 4, 6, 7, 18])\n",
    "# set index to ID to avoid droping it later\n",
    "# 把测试集的id列作为索引，防止误删\n",
    "test  = pd.read_csv(PATH + 'submission.csv').set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_detail_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_pay_time</th>\n",
       "      <th>is_customer_rate</th>\n",
       "      <th>order_detail_goods_num</th>\n",
       "      <th>order_detail_amount</th>\n",
       "      <th>order_detail_discount</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>goods_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306861</th>\n",
       "      <td>3685490</td>\n",
       "      <td>3238357</td>\n",
       "      <td>707.7</td>\n",
       "      <td>2013-01-24 00:24:40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179.8</td>\n",
       "      <td>298.2</td>\n",
       "      <td>2826572</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306862</th>\n",
       "      <td>3685491</td>\n",
       "      <td>3238356</td>\n",
       "      <td>775.9</td>\n",
       "      <td>2012-11-11 17:35:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.9</td>\n",
       "      <td>172.1</td>\n",
       "      <td>2826572</td>\n",
       "      <td>2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306863</th>\n",
       "      <td>3685492</td>\n",
       "      <td>3238357</td>\n",
       "      <td>707.7</td>\n",
       "      <td>2013-01-24 00:24:40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>2826572</td>\n",
       "      <td>3153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306864</th>\n",
       "      <td>3685493</td>\n",
       "      <td>3238356</td>\n",
       "      <td>775.9</td>\n",
       "      <td>2012-11-11 17:35:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2826572</td>\n",
       "      <td>1778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306865</th>\n",
       "      <td>3685494</td>\n",
       "      <td>3238357</td>\n",
       "      <td>707.7</td>\n",
       "      <td>2013-01-24 00:24:40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.9</td>\n",
       "      <td>104.9</td>\n",
       "      <td>2826572</td>\n",
       "      <td>2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306866</th>\n",
       "      <td>3685495</td>\n",
       "      <td>3238358</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2013-01-10 19:24:31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>139.1</td>\n",
       "      <td>2826573</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306867</th>\n",
       "      <td>3685496</td>\n",
       "      <td>3238359</td>\n",
       "      <td>299.8</td>\n",
       "      <td>2013-01-27 15:00:27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>2826574</td>\n",
       "      <td>2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306868</th>\n",
       "      <td>3685497</td>\n",
       "      <td>3238359</td>\n",
       "      <td>299.8</td>\n",
       "      <td>2013-01-27 15:00:27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2826574</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306869</th>\n",
       "      <td>3685498</td>\n",
       "      <td>3238360</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2012-11-11 00:10:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.9</td>\n",
       "      <td>91.1</td>\n",
       "      <td>2826574</td>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306870</th>\n",
       "      <td>3685499</td>\n",
       "      <td>3238361</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2013-07-10 14:22:14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.9</td>\n",
       "      <td>52.1</td>\n",
       "      <td>2826574</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_detail_id  order_id  order_amount       order_pay_time  \\\n",
       "2306861          3685490   3238357         707.7  2013-01-24 00:24:40   \n",
       "2306862          3685491   3238356         775.9  2012-11-11 17:35:05   \n",
       "2306863          3685492   3238357         707.7  2013-01-24 00:24:40   \n",
       "2306864          3685493   3238356         775.9  2012-11-11 17:35:05   \n",
       "2306865          3685494   3238357         707.7  2013-01-24 00:24:40   \n",
       "2306866          3685495   3238358         199.0  2013-01-10 19:24:31   \n",
       "2306867          3685496   3238359         299.8  2013-01-27 15:00:27   \n",
       "2306868          3685497   3238359         299.8  2013-01-27 15:00:27   \n",
       "2306869          3685498   3238360         168.0  2012-11-11 00:10:37   \n",
       "2306870          3685499   3238361         102.0  2013-07-10 14:22:14   \n",
       "\n",
       "         is_customer_rate  order_detail_goods_num  order_detail_amount  \\\n",
       "2306861               0.0                     2.0                179.8   \n",
       "2306862               0.0                     1.0                126.9   \n",
       "2306863               0.0                     1.0                  0.0   \n",
       "2306864               0.0                     1.0                 74.9   \n",
       "2306865               0.0                     1.0                 94.9   \n",
       "2306866               0.0                     1.0                 59.9   \n",
       "2306867               0.0                     1.0                  0.0   \n",
       "2306868               0.0                     1.0                 89.9   \n",
       "2306869               0.0                     1.0                 76.9   \n",
       "2306870               0.0                     1.0                 49.9   \n",
       "\n",
       "         order_detail_discount  customer_id  goods_id  \n",
       "2306861                  298.2      2826572      1478  \n",
       "2306862                  172.1      2826572      2103  \n",
       "2306863                   29.9      2826572      3153  \n",
       "2306864                  105.0      2826572      1778  \n",
       "2306865                  104.9      2826572      2128  \n",
       "2306866                  139.1      2826573      1173  \n",
       "2306867                   59.9      2826574      2513  \n",
       "2306868                  150.0      2826574       998  \n",
       "2306869                   91.1      2826574      1423  \n",
       "2306870                   52.1      2826574      1043  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集概况\n",
    "train[['order_detail_id','order_id','order_amount','order_pay_time','is_customer_rate','order_detail_goods_num','order_detail_amount','order_detail_discount','customer_id','goods_id']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174770"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['customer_id'][train.order_pay_time>'2013-07-31'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2078390"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train.order_pay_time<'2013-07-31'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "y = range(1,2)\n",
    " \n",
    "plt.bar(['not buy','buy'], [1585986-174770,174770], alpha=0.5, width=0.3, color='lightblue', edgecolor='grey', lw=3)\n",
    "plt.title('Sales in August 2013', fontsize=10)\n",
    "for a, b in zip(['not buy','buy'], [1585986-174770,174770]):\n",
    "    plt.text(a, b + 0.05, '%.0f' % b, ha='center', va='bottom', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集使用内容 510.40096282958984 MB\n",
      "测试集使用内存 24.200225830078125 MB\n"
     ]
    }
   ],
   "source": [
    "# 对于特别大的文件，我们需要做一些内存检查\n",
    "mem_train = train.memory_usage(index=True).sum()\n",
    "mem_test=test.memory_usage(index=True).sum()\n",
    "print(u\"训练集使用内容 \"+ str(mem_train/ 1024**2)+\" MB\")\n",
    "print(u\"测试集使用内存 \"+ str(mem_test/ 1024**2)+\" MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 内存优化脚本\n",
    "- 参考[缓解pandas中DataFrame占用内存过大的问题](https://blog.csdn.net/wj1066/article/details/81124959)\n",
    "- 效果非常显著，有效避免内存溢出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# @from: https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65/code\n",
    "# @liscense: Apache 2.0\n",
    "# @author: weijian\n",
    "def reduce_mem_usage(props):\n",
    "    # 计算当前内存\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024 ** 2\n",
    "    print(\"Memory usage of the dataframe is :\", start_mem_usg, \"MB\")\n",
    "    \n",
    "    # 哪些列包含空值，空值用-999填充。why：因为np.nan当做float处理\n",
    "    NAlist = []\n",
    "    for col in props.columns:\n",
    "        # 这里只过滤了objectd格式，如果你的代码中还包含其他类型，请一并过滤\n",
    "        if (props[col].dtypes != object):\n",
    "            \n",
    "            # print(\"**************************\")\n",
    "            # print(\"columns: \", col)\n",
    "            # print(\"dtype before\", props[col].dtype)\n",
    "            \n",
    "            # 判断是否是int类型\n",
    "            isInt = False\n",
    "            mmax = props[col].max()\n",
    "            mmin = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore Na needs to be filled\n",
    "            if not np.isfinite(props[col]).all():\n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(-999, inplace=True) # 用-999填充\n",
    "                \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = np.fabs(props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result < 0.01: # 绝对误差和小于0.01认为可以转换的，要根据task修改\n",
    "                isInt = True\n",
    "            \n",
    "            # make interger / unsigned Integer datatypes\n",
    "            if isInt:\n",
    "                if mmin >= 0: # 最小值大于0，转换成无符号整型\n",
    "                    if mmax <= 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mmax <= 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mmax <= 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else: # 转换成有符号整型\n",
    "                    if mmin > np.iinfo(np.int8).min and mmax < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mmin > np.iinfo(np.int16).min and mmax < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mmin > np.iinfo(np.int32).min and mmax < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mmin > np.iinfo(np.int64).min and mmax < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)  \n",
    "            else: # 注意：这里对于float都转换成float16，需要根据你的情况自己更改\n",
    "                props[col] = props[col].astype(np.float16)\n",
    "            \n",
    "            # print(\"dtype after\", props[col].dtype)\n",
    "            # print(\"********************************\")\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/722zgt1n5r9gk4bm3s2v64_80000gn/T/ipykernel_4620/1606167042.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"is_member_actived\"].fillna(0, inplace=True)\n",
      "/var/folders/3c/722zgt1n5r9gk4bm3s2v64_80000gn/T/ipykernel_4620/1606167042.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"member_status\"].fillna(0, inplace=True)\n",
      "/var/folders/3c/722zgt1n5r9gk4bm3s2v64_80000gn/T/ipykernel_4620/1606167042.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"customer_gender\"].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%Y-%m-%d\": \" 11:08:07\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_detail_status\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_detail_status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 处理日期\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoods_list_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgoods_list_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_pay_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_pay_time\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoods_delist_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoods_delist_time\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/dm/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/dm/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/dm/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/dm/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:587\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%Y-%m-%d\": \" 11:08:07\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# 处理id字段\n",
    "train['order_detail_id'] = train['order_detail_id'].astype(np.uint32)\n",
    "train['order_id'] = train['order_id'].astype(np.uint32)\n",
    "train['customer_id'] = train['customer_id'].astype(np.uint32)\n",
    "train['goods_id'] = train['goods_id'].astype(np.uint32)\n",
    "train['goods_class_id'] = train['goods_class_id'].astype(np.uint32)\n",
    "train['member_id'] = train['member_id'].astype(np.uint32)\n",
    "# 处理状态字段，这里同时处理空值，将空值置为0\n",
    "train['order_status'] = train['order_status'].astype(np.uint8)\n",
    "train['goods_has_discount'] = train['goods_has_discount'].astype(np.uint8)\n",
    "train[\"is_member_actived\"].fillna(0, inplace=True)\n",
    "train[\"is_member_actived\"]=train[\"is_member_actived\"].astype(np.int8)\n",
    "train[\"member_status\"].fillna(0, inplace=True)\n",
    "train[\"member_status\"]=train[\"member_status\"].astype(np.int8)\n",
    "train[\"customer_gender\"].fillna(0, inplace=True)\n",
    "train[\"customer_gender\"]=train[\"customer_gender\"].astype(np.int8)\n",
    "train['is_customer_rate'] = train['is_customer_rate'].astype(np.uint8)\n",
    "train['order_detail_status'] = train['order_detail_status'].astype(np.uint8)\n",
    "# 处理日期\n",
    "train['goods_list_time']=pd.to_datetime(train['goods_list_time'],format=\"%Y-%m-%d\")\n",
    "train['order_pay_time']=pd.to_datetime(train['order_pay_time'],format=\"%Y-%m-%d\")\n",
    "train['goods_delist_time']=pd.to_datetime(train['goods_delist_time'],format=\"%Y-%m-%d\")\n",
    "# 检查内存使用\n",
    "mem_train = train.memory_usage(index=True).sum()\n",
    "mem_test=test.memory_usage(index=True).sum()\n",
    "print(u\"训练集使用内容 \"+ str(mem_train/ 1024**2)+\" MB\")\n",
    "print(u\"测试集使用内存 \"+ str(mem_test/ 1024**2)+\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train['customer_city_id'] = LabelEncoder().fit_transform(train['customer_city'].astype(str))\n",
    "# train['customer_province_id'] = LabelEncoder().fit_transform(train['customer_province'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 构造时间滑窗特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 每日付款金额"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/722zgt1n5r9gk4bm3s2v64_80000gn/T/ipykernel_4620/4022739742.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.DatetimeIndex(df['order_pay_time']).date\n"
     ]
    }
   ],
   "source": [
    "# 将用户下单金额按天进行汇总\n",
    "# df = train[train.order_status<101][train.order_pay_time>'2013-02-01']\n",
    "df = train[train.order_pay_time>'2013-02-01']\n",
    "df['date'] = pd.DatetimeIndex(df['order_pay_time']).date\n",
    "df_payment = df[['customer_id','date','order_total_payment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685471"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_payment['customer_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "注意，成功交易的客户数量不等于全部客户数量，说明有相当一部分客户虽然下过单，但是没有成功的订单，那么这些客户自然应当算在训练集之外。\n",
    "数据合并时，由于`test.csv`中，已经设置了默认0值，只需要和训练后的预测标签做一个`left join`就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_payment = df_payment.groupby(['date','customer_id']).agg({'order_total_payment': ['sum']})\n",
    "df_payment.columns = ['day_total_payment']\n",
    "df_payment.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_payment = df_payment.set_index(\n",
    "    [\"customer_id\", \"date\"])[[\"day_total_payment\"]].unstack(level=-1).fillna(0)\n",
    "df_payment.columns = df_payment.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 每日购买商品数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_goods = df[['customer_id','date','order_total_num']]\n",
    "df_goods = df_goods.groupby(['date','customer_id']).agg({'order_total_num': ['sum']})\n",
    "df_goods.columns = ['day_total_num']\n",
    "df_goods.reset_index(inplace=True)\n",
    "df_goods = df_goods.set_index(\n",
    "    [\"customer_id\", \"date\"])[[\"day_total_num\"]].unstack(level=-1).fillna(0)\n",
    "df_goods.columns = df_goods.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "该场景每天都有成交记录，这样就不需要考虑生成完整时间段填充的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这是一个时间滑窗函数，获得dt之前minus天以来periods的dataframe，以便进一步计算\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. 构造dataset这里有个取巧的地方，因为要预测的9月份除了开学季以外不是非常特殊的月份，因此主要考虑近期的因素，数据集的开始时间也是2月1日，尽量避免了双十一、元旦假期的影响，当然春节假期继续保留。同时，构造数据集的时候保留了customer_id，主要为了与其它特征做整合。\n",
    "2. 通过一个函数整合付款金额和商品数量的时间滑窗，主要是因为分开做到时候合并占用内存更大，并且函数最后在返回值处做了内存优化，用时间代价尽可能避免内存溢出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(df_payment, df_goods, t2018, is_train=True):\n",
    "    X = {}\n",
    "    # 整合用户id\n",
    "    tmp = df_payment.reset_index()\n",
    "    X['customer_id'] = tmp['customer_id']\n",
    "    # 消费特征\n",
    "    print('Preparing payment feature...')\n",
    "    for i in [14,30,60,91]:\n",
    "        tmp = get_timespan(df_payment, t2018, i, i)\n",
    "        # X['diff_%s_mean' % i] = tmp_1.diff(axis=1).mean(axis=1).values\n",
    "        X['mean_%s_decay' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        # X['mean_%s' % i] = tmp_1.mean(axis=1).values\n",
    "        # X['median_%s' % i] = tmp.median(axis=1).values\n",
    "        # X['min_%s' % i] = tmp_1.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values\n",
    "        # X['std_%s' % i] = tmp_1.std(axis=1).values\n",
    "        X['sum_%s' % i] = tmp.sum(axis=1).values\n",
    "    for i in [14,30,60,91]:\n",
    "        tmp = get_timespan(df_payment, t2018 + timedelta(days=-7), i, i)\n",
    "        X['mean_%s_decay_2' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        # X['mean_%s_2' % i] = tmp_2.mean(axis=1).values\n",
    "        # X['median_%s_2' % i] = tmp.median(axis=1).values\n",
    "        # X['min_%s_2' % i] = tmp_2.min(axis=1).values\n",
    "        X['max_%s_2' % i] = tmp.max(axis=1).values\n",
    "        # X['std_%s_2' % i] = tmp_2.std(axis=1).values\n",
    "    for i in [14,30,60,91]:\n",
    "        tmp = get_timespan(df_payment, t2018, i, i)\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp != 0).sum(axis=1).values\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp != 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp != 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    # 对此处进行微调，主要考虑近期因素\n",
    "    for i in range(1, 4):\n",
    "        X['day_%s_2018' % i] = get_timespan(df_payment, t2018, i*30, 30).sum(axis=1).values\n",
    "    # 商品数量特征，这里故意把时间和消费特征错开，提高时间滑窗的覆盖面\n",
    "    print('Preparing num feature...')\n",
    "    for i in [21,49,84]:\n",
    "            tmp = get_timespan(df_goods, t2018, i, i)\n",
    "            # X['goods_diff_%s_mean' % i] = tmp_1.diff(axis=1).mean(axis=1).values\n",
    "            # X['goods_mean_%s_decay' % i] = (tmp_1 * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "            X['goods_mean_%s' % i] = tmp.mean(axis=1).values\n",
    "            # X['goods_median_%s' % i] = tmp.median(axis=1).values\n",
    "            # X['goods_min_%s' % i] = tmp_1.min(axis=1).values\n",
    "            X['goods_max_%s' % i] = tmp.max(axis=1).values\n",
    "            # X['goods_std_%s' % i] = tmp_1.std(axis=1).values\n",
    "            X['goods_sum_%s' % i] = tmp.sum(axis=1).values\n",
    "    for i in [21,49,84]:    \n",
    "            tmp = get_timespan(df_goods, t2018 + timedelta(weeks=-1), i, i)\n",
    "            # X['goods_diff_%s_mean_2' % i] = tmp_2.diff(axis=1).mean(axis=1).values\n",
    "            # X['goods_mean_%s_decay_2' % i] = (tmp_2 * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "            X['goods_mean_%s_2' % i] = tmp.mean(axis=1).values\n",
    "            # X['goods_median_%s_2' % i] = tmp.median(axis=1).values\n",
    "            # X['goods_min_%s_2' % i] = tmp_2.min(axis=1).values\n",
    "            X['goods_max_%s_2' % i] = tmp.max(axis=1).values\n",
    "            X['goods_sum_%s_2' % i] = tmp.sum(axis=1).values\n",
    "    for i in [21,49,84]:    \n",
    "            tmp = get_timespan(df_goods, t2018, i, i)\n",
    "            X['goods_has_sales_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "            X['goods_last_has_sales_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "            X['goods_first_has_sales_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "\n",
    "    # 对此处进行微调，主要考虑近期因素\n",
    "    for i in range(1, 4):\n",
    "        X['goods_day_%s_2018' % i] = get_timespan(df_goods, t2018, i*28, 28).sum(axis=1).values\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    reduce_mem_usage(X)\n",
    "    \n",
    "    if is_train:\n",
    "        # 这样转换之后，打标签直接用numpy切片就可以了\n",
    "        # 当然这里前提是确认付款总额没有负数的问题\n",
    "        X['label'] = df_goods[pd.date_range(t2018, periods=30)].max(axis=1).values\n",
    "        X['label'][X['label'] > 0] = 1\n",
    "        return X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_days = 4\n",
    "t2017 = date(2013, 7, 1)\n",
    "X_l, y_l = [], []\n",
    "for i in range(num_days):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    # X_tmp, y_tmp = prepare_dataset(df_payment, df_goods, t2017 + delta)\n",
    "    X_tmp = prepare_dataset(df_payment, df_goods, t2017 + delta)\n",
    "    X_tmp = pd.concat([X_tmp], axis=1)\n",
    "\n",
    "    X_l.append(X_tmp)\n",
    "    # y_l.append(y_tmp)\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "# y_train = np.concatenate(y_l, axis=0)\n",
    "\n",
    "del X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 345.16217041015625 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  73.86999416351318  MB\n",
      "This is  21.40153252476465 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "X_test = prepare_dataset(df_payment, df_goods, date(2013, 9, 1), is_train=False)\n",
    "X_test = pd.concat([X_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 中间结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.to_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 训练&推理 - 训练配置以及训练\n",
    "### 加载特征工程结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('X_train.csv',usecols=['max_30','has_sales_days_in_last_30','first_has_sales_day_in_last_60','goods_sum_49','label'])\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_train.drop(['Unnamed: 0','customer_id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val = pd.read_csv('X_val.csv')\n",
    "X_val.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('X_test.csv')\n",
    "# X_test = pd.read_csv('X_test.csv',usecols=['max_30','has_sales_days_in_last_30','first_has_sales_day_in_last_60','goods_sum_49'])\n",
    "X_test.drop(['Unnamed: 0','customer_id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_14_decay</th>\n",
       "      <th>max_14</th>\n",
       "      <th>sum_14</th>\n",
       "      <th>mean_30_decay</th>\n",
       "      <th>max_30</th>\n",
       "      <th>sum_30</th>\n",
       "      <th>mean_60_decay</th>\n",
       "      <th>max_60</th>\n",
       "      <th>sum_60</th>\n",
       "      <th>mean_91_decay</th>\n",
       "      <th>...</th>\n",
       "      <th>goods_has_sales_days_in_last_49</th>\n",
       "      <th>goods_last_has_sales_day_in_last_49</th>\n",
       "      <th>goods_first_has_sales_day_in_last_49</th>\n",
       "      <th>goods_has_sales_days_in_last_84</th>\n",
       "      <th>goods_last_has_sales_day_in_last_84</th>\n",
       "      <th>goods_first_has_sales_day_in_last_84</th>\n",
       "      <th>goods_day_1_2018</th>\n",
       "      <th>goods_day_2_2018</th>\n",
       "      <th>goods_day_3_2018</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.537</td>\n",
       "      <td>39.9</td>\n",
       "      <td>39.9</td>\n",
       "      <td>3.537</td>\n",
       "      <td>39.9</td>\n",
       "      <td>39.9</td>\n",
       "      <td>3.537</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.530</td>\n",
       "      <td>98.9</td>\n",
       "      <td>197.8</td>\n",
       "      <td>2.530</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_14_decay  max_14  sum_14  mean_30_decay  max_30  sum_30  \\\n",
       "0            0.0     0.0     0.0          0.000     0.0     0.0   \n",
       "1            0.0     0.0     0.0          0.000     0.0     0.0   \n",
       "2            0.0     0.0     0.0          3.537    39.9    39.9   \n",
       "3            0.0     0.0     0.0          0.000     0.0     0.0   \n",
       "4            0.0     0.0     0.0          0.000     0.0     0.0   \n",
       "\n",
       "   mean_60_decay  max_60  sum_60  mean_91_decay  ...    \\\n",
       "0          0.000     0.0     0.0          0.000  ...     \n",
       "1          0.000     0.0     0.0          0.000  ...     \n",
       "2          3.537    39.9    39.9          3.537  ...     \n",
       "3          0.000     0.0     0.0          0.000  ...     \n",
       "4          2.530    98.9   197.8          2.530  ...     \n",
       "\n",
       "   goods_has_sales_days_in_last_49  goods_last_has_sales_day_in_last_49  \\\n",
       "0                                0                                   49   \n",
       "1                                0                                   49   \n",
       "2                                1                                   24   \n",
       "3                                0                                   49   \n",
       "4                                1                                   37   \n",
       "\n",
       "   goods_first_has_sales_day_in_last_49  goods_has_sales_days_in_last_84  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                    24                                1   \n",
       "3                                     0                                0   \n",
       "4                                    37                                2   \n",
       "\n",
       "   goods_last_has_sales_day_in_last_84  goods_first_has_sales_day_in_last_84  \\\n",
       "0                                   84                                     0   \n",
       "1                                   84                                     0   \n",
       "2                                   24                                    24   \n",
       "3                                   84                                     0   \n",
       "4                                   37                                    56   \n",
       "\n",
       "   goods_day_1_2018  goods_day_2_2018  goods_day_3_2018  label  \n",
       "0                 0                 0                 0    0.0  \n",
       "1                 0                 0                 0    0.0  \n",
       "2                 1                 0                 0    0.0  \n",
       "3                 0                 0                 0    1.0  \n",
       "4                 0                 2                 0    1.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 选取参与训练的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_14_decay', 'max_14', 'sum_14', 'mean_30_decay', 'max_30',\n",
      "       'sum_30', 'mean_60_decay', 'max_60', 'sum_60', 'mean_91_decay',\n",
      "       'max_91', 'sum_91', 'mean_14_decay_2', 'max_14_2', 'mean_30_decay_2',\n",
      "       'max_30_2', 'mean_60_decay_2', 'max_60_2', 'mean_91_decay_2',\n",
      "       'max_91_2', 'has_sales_days_in_last_14',\n",
      "       'last_has_sales_day_in_last_14', 'first_has_sales_day_in_last_14',\n",
      "       'has_sales_days_in_last_30', 'last_has_sales_day_in_last_30',\n",
      "       'first_has_sales_day_in_last_30', 'has_sales_days_in_last_60',\n",
      "       'last_has_sales_day_in_last_60', 'first_has_sales_day_in_last_60',\n",
      "       'has_sales_days_in_last_91', 'last_has_sales_day_in_last_91',\n",
      "       'first_has_sales_day_in_last_91', 'day_1_2018', 'day_2_2018',\n",
      "       'day_3_2018', 'goods_mean_21', 'goods_max_21', 'goods_sum_21',\n",
      "       'goods_mean_49', 'goods_max_49', 'goods_sum_49', 'goods_mean_84',\n",
      "       'goods_max_84', 'goods_sum_84', 'goods_mean_21_2', 'goods_max_21_2',\n",
      "       'goods_sum_21_2', 'goods_mean_49_2', 'goods_max_49_2', 'goods_sum_49_2',\n",
      "       'goods_mean_84_2', 'goods_max_84_2', 'goods_sum_84_2',\n",
      "       'goods_has_sales_days_in_last_21',\n",
      "       'goods_last_has_sales_day_in_last_21',\n",
      "       'goods_first_has_sales_day_in_last_21',\n",
      "       'goods_has_sales_days_in_last_49',\n",
      "       'goods_last_has_sales_day_in_last_49',\n",
      "       'goods_first_has_sales_day_in_last_49',\n",
      "       'goods_has_sales_days_in_last_84',\n",
      "       'goods_last_has_sales_day_in_last_84',\n",
      "       'goods_first_has_sales_day_in_last_84', 'goods_day_1_2018',\n",
      "       'goods_day_2_2018', 'goods_day_3_2018', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train[['has_sales_days_in_last_14',\n",
    "       'last_has_sales_day_in_last_14', 'first_has_sales_day_in_last_14',\n",
    "       'has_sales_days_in_last_30', 'last_has_sales_day_in_last_30',\n",
    "       'first_has_sales_day_in_last_30', 'has_sales_days_in_last_60',\n",
    "       'last_has_sales_day_in_last_60', 'first_has_sales_day_in_last_60',\n",
    "       'has_sales_days_in_last_91', 'last_has_sales_day_in_last_91','goods_mean_21', 'goods_max_21', 'goods_sum_21',\n",
    "       'goods_mean_49', 'goods_max_49', 'goods_sum_49', 'goods_mean_84',\n",
    "       'goods_max_84', 'goods_sum_84', 'goods_mean_21_2', 'goods_max_21_2',\n",
    "       'goods_sum_21_2', 'goods_mean_49_2', 'goods_max_49_2', 'goods_sum_49_2',\n",
    "       'goods_mean_84_2', 'goods_max_84_2', 'goods_sum_84_2',\n",
    "       'goods_has_sales_days_in_last_21',\n",
    "       'goods_last_has_sales_day_in_last_21',\n",
    "       'goods_first_has_sales_day_in_last_21',\n",
    "       'goods_has_sales_days_in_last_49',\n",
    "       'goods_last_has_sales_day_in_last_49',\n",
    "       'goods_first_has_sales_day_in_last_49',\n",
    "       'goods_has_sales_days_in_last_84',\n",
    "       'goods_last_has_sales_day_in_last_84',\n",
    "       'goods_first_has_sales_day_in_last_84', 'goods_day_1_2018',\n",
    "       'goods_day_2_2018', 'goods_day_3_2018','label']]\n",
    "X_test = X_test[['has_sales_days_in_last_14',\n",
    "       'last_has_sales_day_in_last_14', 'first_has_sales_day_in_last_14',\n",
    "       'has_sales_days_in_last_30', 'last_has_sales_day_in_last_30',\n",
    "       'first_has_sales_day_in_last_30', 'has_sales_days_in_last_60',\n",
    "       'last_has_sales_day_in_last_60', 'first_has_sales_day_in_last_60',\n",
    "       'has_sales_days_in_last_91', 'last_has_sales_day_in_last_91','goods_mean_21', 'goods_max_21', 'goods_sum_21',\n",
    "       'goods_mean_49', 'goods_max_49', 'goods_sum_49', 'goods_mean_84',\n",
    "       'goods_max_84', 'goods_sum_84', 'goods_mean_21_2', 'goods_max_21_2',\n",
    "       'goods_sum_21_2', 'goods_mean_49_2', 'goods_max_49_2', 'goods_sum_49_2',\n",
    "       'goods_mean_84_2', 'goods_max_84_2', 'goods_sum_84_2',\n",
    "       'goods_has_sales_days_in_last_21',\n",
    "       'goods_last_has_sales_day_in_last_21',\n",
    "       'goods_first_has_sales_day_in_last_21',\n",
    "       'goods_has_sales_days_in_last_49',\n",
    "       'goods_last_has_sales_day_in_last_49',\n",
    "       'goods_first_has_sales_day_in_last_49',\n",
    "       'goods_has_sales_days_in_last_84',\n",
    "       'goods_last_has_sales_day_in_last_84',\n",
    "       'goods_first_has_sales_day_in_last_84', 'goods_day_1_2018',\n",
    "       'goods_day_2_2018', 'goods_day_3_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_test = (X_test - X_test.min()) / (X_test.max() - X_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 前面标签也被归一化了，还原\n",
    "X_train['label'][X_train['label'] > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据分割\n",
    "def load_data(df,istrain):\n",
    "    # data = np.fromfile(datafile)\n",
    "    data = df\n",
    "\n",
    "    feature_num = len(data.columns)\n",
    "    # 将原始数据进行Reshape\n",
    "    data = np.array(data)\n",
    "    data = data.reshape([-1, feature_num])\n",
    "    \n",
    "    # 训练集和测试集的划分比例\n",
    "    #ratio = 0.8\n",
    "    if istrain == True:\n",
    "        ratio = 0.8\n",
    "        offset = int(data.shape[0] * ratio)\n",
    "        training_data = data[:offset]\n",
    "        test_data = data[offset:]\n",
    "    else:\n",
    "        training_data = data\n",
    "        test_data = None\n",
    "\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set done.\n",
      "test set done.\n"
     ]
    }
   ],
   "source": [
    "# 加载处理后的数据\n",
    "training_data, test_data = load_data(X_train,True)\n",
    "print('train set done.')\n",
    "\n",
    "pre_data, none = load_data(X_test,False)\n",
    "print('test set done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 搭建多层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 构建多层神经网络\n",
    "class Regressor(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(Regressor, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        # 定义三层全连接层，输出维度是1，激活函数为relu\n",
    "        self.fc1 = Linear(input_dim=41, output_dim=128, act='relu') # 输入层，input dim 为数据维度大小\n",
    "        self.fc2 = Linear(input_dim=128, output_dim=128, act='relu')\n",
    "        self.fc3 = Linear(input_dim=128, output_dim=1, act='sigmoid')\n",
    "    # 网络的前向计算函数\n",
    "    def forward(self, inputs):\n",
    "        fc1 = self.fc1(inputs)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        x = self.fc3(fc2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    # 声明定义好的线性回归模型\n",
    "    model = Regressor(\"Regressor\")\n",
    "    # 开启模型训练模式\n",
    "    model.train()\n",
    "    # 定义优化算法，这里使用Adam Optimizer\n",
    "    # 学习率设置为0.00001\n",
    "    opt = fluid.optimizer.Adam(learning_rate=0.00001, parameter_list=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用类别权重对数据不平衡问题进行处理\n",
    "def wce_loss(pred, label, w=48, epsilon=1e-05): # w 是给到 y=1 类别的权重，越大越重视\n",
    "    label = fluid.layers.clip(label, epsilon, 1-epsilon)\n",
    "    pred = fluid.layers.clip(pred, epsilon, 1-epsilon)\n",
    "\n",
    "    loss = -1 * (w * label * fluid.layers.log(pred) + (1 - label) * fluid.layers.log(1 - pred))\n",
    "    loss = fluid.layers.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss is: [6.4240947]\n",
      "epoch: 0, iter: 20, loss is: [5.585197]\n",
      "epoch: 0, iter: 40, loss is: [5.9884305]\n",
      "epoch: 0, iter: 60, loss is: [5.601056]\n",
      "epoch: 0, iter: 80, loss is: [5.5771275]\n",
      "epoch: 0, iter: 100, loss is: [5.566127]\n",
      "epoch: 0, iter: 120, loss is: [5.829499]\n",
      "epoch: 0, iter: 140, loss is: [5.45304]\n",
      "epoch: 0, iter: 160, loss is: [5.3009186]\n",
      "epoch: 0, iter: 180, loss is: [4.9718328]\n",
      "epoch: 0, iter: 200, loss is: [5.0031395]\n",
      "epoch: 0, iter: 220, loss is: [4.9489536]\n",
      "epoch: 0, iter: 240, loss is: [4.632763]\n",
      "epoch: 0, iter: 260, loss is: [4.880851]\n",
      "epoch: 0, iter: 280, loss is: [4.8238106]\n",
      "epoch: 0, iter: 300, loss is: [4.730828]\n",
      "epoch: 0, iter: 320, loss is: [4.7572412]\n",
      "epoch: 0, iter: 340, loss is: [4.4746714]\n",
      "epoch: 0, iter: 360, loss is: [4.5569715]\n",
      "epoch: 0, iter: 380, loss is: [4.664049]\n",
      "epoch: 0, iter: 400, loss is: [4.577633]\n",
      "epoch: 0, iter: 420, loss is: [4.354995]\n",
      "epoch: 0, iter: 440, loss is: [4.148847]\n",
      "epoch: 0, iter: 460, loss is: [4.207163]\n",
      "epoch: 0, iter: 480, loss is: [4.2027264]\n",
      "epoch: 0, iter: 500, loss is: [4.162389]\n",
      "epoch: 0, iter: 520, loss is: [4.1965904]\n",
      "epoch: 1, iter: 0, loss is: [4.07926]\n",
      "epoch: 1, iter: 20, loss is: [4.0202265]\n",
      "epoch: 1, iter: 40, loss is: [3.9099112]\n",
      "epoch: 1, iter: 60, loss is: [3.801144]\n",
      "epoch: 1, iter: 80, loss is: [3.8001595]\n",
      "epoch: 1, iter: 100, loss is: [4.0130396]\n",
      "epoch: 1, iter: 120, loss is: [3.9429972]\n",
      "epoch: 1, iter: 140, loss is: [3.7822685]\n",
      "epoch: 1, iter: 160, loss is: [3.700629]\n",
      "epoch: 1, iter: 180, loss is: [3.7718396]\n",
      "epoch: 1, iter: 200, loss is: [3.6418982]\n",
      "epoch: 1, iter: 220, loss is: [3.448235]\n",
      "epoch: 1, iter: 240, loss is: [3.4688768]\n",
      "epoch: 1, iter: 260, loss is: [3.3847876]\n",
      "epoch: 1, iter: 280, loss is: [3.5390084]\n",
      "epoch: 1, iter: 300, loss is: [3.3362772]\n",
      "epoch: 1, iter: 320, loss is: [3.4034991]\n",
      "epoch: 1, iter: 340, loss is: [3.3354053]\n",
      "epoch: 1, iter: 360, loss is: [3.2428427]\n",
      "epoch: 1, iter: 380, loss is: [3.4139078]\n",
      "epoch: 1, iter: 400, loss is: [3.242897]\n",
      "epoch: 1, iter: 420, loss is: [3.349173]\n",
      "epoch: 1, iter: 440, loss is: [3.1568334]\n",
      "epoch: 1, iter: 460, loss is: [3.1726613]\n",
      "epoch: 1, iter: 480, loss is: [3.0886765]\n",
      "epoch: 1, iter: 500, loss is: [3.0067182]\n",
      "epoch: 1, iter: 520, loss is: [3.0618722]\n",
      "epoch: 2, iter: 0, loss is: [3.127273]\n",
      "epoch: 2, iter: 20, loss is: [3.0482788]\n",
      "epoch: 2, iter: 40, loss is: [3.0548625]\n",
      "epoch: 2, iter: 60, loss is: [3.067195]\n",
      "epoch: 2, iter: 80, loss is: [3.1149228]\n",
      "epoch: 2, iter: 100, loss is: [3.0307221]\n",
      "epoch: 2, iter: 120, loss is: [2.952599]\n",
      "epoch: 2, iter: 140, loss is: [2.9610784]\n",
      "epoch: 2, iter: 160, loss is: [3.0602787]\n",
      "epoch: 2, iter: 180, loss is: [2.892705]\n",
      "epoch: 2, iter: 200, loss is: [2.9323664]\n",
      "epoch: 2, iter: 220, loss is: [2.9013243]\n",
      "epoch: 2, iter: 240, loss is: [2.9746294]\n",
      "epoch: 2, iter: 260, loss is: [2.8598642]\n",
      "epoch: 2, iter: 280, loss is: [2.856443]\n",
      "epoch: 2, iter: 300, loss is: [2.9518285]\n",
      "epoch: 2, iter: 320, loss is: [2.8128805]\n",
      "epoch: 2, iter: 340, loss is: [2.7803547]\n",
      "epoch: 2, iter: 360, loss is: [2.8005772]\n",
      "epoch: 2, iter: 380, loss is: [2.73322]\n",
      "epoch: 2, iter: 400, loss is: [2.8321157]\n",
      "epoch: 2, iter: 420, loss is: [2.758816]\n",
      "epoch: 2, iter: 440, loss is: [2.7033894]\n",
      "epoch: 2, iter: 460, loss is: [2.8371618]\n",
      "epoch: 2, iter: 480, loss is: [2.7163641]\n",
      "epoch: 2, iter: 500, loss is: [2.661222]\n",
      "epoch: 2, iter: 520, loss is: [2.7690396]\n",
      "epoch: 3, iter: 0, loss is: [2.7751338]\n",
      "epoch: 3, iter: 20, loss is: [2.6396594]\n",
      "epoch: 3, iter: 40, loss is: [2.8137894]\n",
      "epoch: 3, iter: 60, loss is: [2.6233706]\n",
      "epoch: 3, iter: 80, loss is: [2.6597905]\n",
      "epoch: 3, iter: 100, loss is: [2.7182941]\n",
      "epoch: 3, iter: 120, loss is: [2.6200886]\n",
      "epoch: 3, iter: 140, loss is: [2.672626]\n",
      "epoch: 3, iter: 160, loss is: [2.6653142]\n",
      "epoch: 3, iter: 180, loss is: [2.6031542]\n",
      "epoch: 3, iter: 200, loss is: [2.5703683]\n",
      "epoch: 3, iter: 220, loss is: [2.689561]\n",
      "epoch: 3, iter: 240, loss is: [2.6024244]\n",
      "epoch: 3, iter: 260, loss is: [2.5442743]\n",
      "epoch: 3, iter: 280, loss is: [2.6512644]\n",
      "epoch: 3, iter: 300, loss is: [2.656393]\n",
      "epoch: 3, iter: 320, loss is: [2.577458]\n",
      "epoch: 3, iter: 340, loss is: [2.6193027]\n",
      "epoch: 3, iter: 360, loss is: [2.601707]\n",
      "epoch: 3, iter: 380, loss is: [2.63043]\n",
      "epoch: 3, iter: 400, loss is: [2.6402764]\n",
      "epoch: 3, iter: 420, loss is: [2.5906703]\n",
      "epoch: 3, iter: 440, loss is: [2.5792325]\n",
      "epoch: 3, iter: 460, loss is: [2.636031]\n",
      "epoch: 3, iter: 480, loss is: [2.579682]\n",
      "epoch: 3, iter: 500, loss is: [2.5580297]\n",
      "epoch: 3, iter: 520, loss is: [2.5909739]\n",
      "epoch: 4, iter: 0, loss is: [2.5862708]\n",
      "epoch: 4, iter: 20, loss is: [2.5749733]\n",
      "epoch: 4, iter: 40, loss is: [2.591743]\n",
      "epoch: 4, iter: 60, loss is: [2.5288851]\n",
      "epoch: 4, iter: 80, loss is: [2.5614316]\n",
      "epoch: 4, iter: 100, loss is: [2.5763588]\n",
      "epoch: 4, iter: 120, loss is: [2.5864778]\n",
      "epoch: 4, iter: 140, loss is: [2.5501842]\n",
      "epoch: 4, iter: 160, loss is: [2.5376945]\n",
      "epoch: 4, iter: 180, loss is: [2.5886207]\n",
      "epoch: 4, iter: 200, loss is: [2.5548065]\n",
      "epoch: 4, iter: 220, loss is: [2.5277772]\n",
      "epoch: 4, iter: 240, loss is: [2.5465963]\n",
      "epoch: 4, iter: 260, loss is: [2.5210433]\n",
      "epoch: 4, iter: 280, loss is: [2.4726996]\n",
      "epoch: 4, iter: 300, loss is: [2.5303473]\n",
      "epoch: 4, iter: 320, loss is: [2.5506155]\n",
      "epoch: 4, iter: 340, loss is: [2.538394]\n",
      "epoch: 4, iter: 360, loss is: [2.5208945]\n",
      "epoch: 4, iter: 380, loss is: [2.5519247]\n",
      "epoch: 4, iter: 400, loss is: [2.5016341]\n",
      "epoch: 4, iter: 420, loss is: [2.5190346]\n",
      "epoch: 4, iter: 440, loss is: [2.4723856]\n",
      "epoch: 4, iter: 460, loss is: [2.4918041]\n",
      "epoch: 4, iter: 480, loss is: [2.5193434]\n",
      "epoch: 4, iter: 500, loss is: [2.5019712]\n",
      "epoch: 4, iter: 520, loss is: [2.5535963]\n",
      "epoch: 5, iter: 0, loss is: [2.5192423]\n",
      "epoch: 5, iter: 20, loss is: [2.4880118]\n",
      "epoch: 5, iter: 40, loss is: [2.528103]\n",
      "epoch: 5, iter: 60, loss is: [2.5194523]\n",
      "epoch: 5, iter: 80, loss is: [2.5244672]\n",
      "epoch: 5, iter: 100, loss is: [2.5199718]\n",
      "epoch: 5, iter: 120, loss is: [2.5191855]\n",
      "epoch: 5, iter: 140, loss is: [2.5223126]\n",
      "epoch: 5, iter: 160, loss is: [2.4622655]\n",
      "epoch: 5, iter: 180, loss is: [2.5173492]\n",
      "epoch: 5, iter: 200, loss is: [2.4624987]\n",
      "epoch: 5, iter: 220, loss is: [2.48531]\n",
      "epoch: 5, iter: 240, loss is: [2.5072489]\n",
      "epoch: 5, iter: 260, loss is: [2.497651]\n",
      "epoch: 5, iter: 280, loss is: [2.4605427]\n",
      "epoch: 5, iter: 300, loss is: [2.4731839]\n",
      "epoch: 5, iter: 320, loss is: [2.5205612]\n",
      "epoch: 5, iter: 340, loss is: [2.5066836]\n",
      "epoch: 5, iter: 360, loss is: [2.4659953]\n",
      "epoch: 5, iter: 380, loss is: [2.4585686]\n",
      "epoch: 5, iter: 400, loss is: [2.4954004]\n",
      "epoch: 5, iter: 420, loss is: [2.4608226]\n",
      "epoch: 5, iter: 440, loss is: [2.4878726]\n",
      "epoch: 5, iter: 460, loss is: [2.49437]\n",
      "epoch: 5, iter: 480, loss is: [2.4524026]\n",
      "epoch: 5, iter: 500, loss is: [2.485425]\n",
      "epoch: 5, iter: 520, loss is: [2.4646275]\n",
      "epoch: 6, iter: 0, loss is: [2.4515579]\n",
      "epoch: 6, iter: 20, loss is: [2.4803596]\n",
      "epoch: 6, iter: 40, loss is: [2.493429]\n",
      "epoch: 6, iter: 60, loss is: [2.4760303]\n",
      "epoch: 6, iter: 80, loss is: [2.4723954]\n",
      "epoch: 6, iter: 100, loss is: [2.5067585]\n",
      "epoch: 6, iter: 120, loss is: [2.4977047]\n",
      "epoch: 6, iter: 140, loss is: [2.509264]\n",
      "epoch: 6, iter: 160, loss is: [2.5145354]\n",
      "epoch: 6, iter: 180, loss is: [2.5087733]\n",
      "epoch: 6, iter: 200, loss is: [2.4753468]\n",
      "epoch: 6, iter: 220, loss is: [2.50289]\n",
      "epoch: 6, iter: 240, loss is: [2.4835851]\n",
      "epoch: 6, iter: 260, loss is: [2.455459]\n",
      "epoch: 6, iter: 280, loss is: [2.4639163]\n",
      "epoch: 6, iter: 300, loss is: [2.4773989]\n",
      "epoch: 6, iter: 320, loss is: [2.4441385]\n",
      "epoch: 6, iter: 340, loss is: [2.540493]\n",
      "epoch: 6, iter: 360, loss is: [2.5120866]\n",
      "epoch: 6, iter: 380, loss is: [2.4971485]\n",
      "epoch: 6, iter: 400, loss is: [2.4804764]\n",
      "epoch: 6, iter: 420, loss is: [2.436938]\n",
      "epoch: 6, iter: 440, loss is: [2.3714228]\n",
      "epoch: 6, iter: 460, loss is: [2.509347]\n",
      "epoch: 6, iter: 480, loss is: [2.442787]\n",
      "epoch: 6, iter: 500, loss is: [2.5134282]\n",
      "epoch: 6, iter: 520, loss is: [2.475596]\n",
      "epoch: 7, iter: 0, loss is: [2.4379468]\n",
      "epoch: 7, iter: 20, loss is: [2.4360018]\n",
      "epoch: 7, iter: 40, loss is: [2.4724762]\n",
      "epoch: 7, iter: 60, loss is: [2.453781]\n",
      "epoch: 7, iter: 80, loss is: [2.500041]\n",
      "epoch: 7, iter: 100, loss is: [2.4851885]\n",
      "epoch: 7, iter: 120, loss is: [2.442673]\n",
      "epoch: 7, iter: 140, loss is: [2.4288867]\n",
      "epoch: 7, iter: 160, loss is: [2.404556]\n",
      "epoch: 7, iter: 180, loss is: [2.4456916]\n",
      "epoch: 7, iter: 200, loss is: [2.417398]\n",
      "epoch: 7, iter: 220, loss is: [2.4615467]\n",
      "epoch: 7, iter: 240, loss is: [2.5133011]\n",
      "epoch: 7, iter: 260, loss is: [2.4389467]\n",
      "epoch: 7, iter: 280, loss is: [2.4543583]\n",
      "epoch: 7, iter: 300, loss is: [2.4108672]\n",
      "epoch: 7, iter: 320, loss is: [2.4954054]\n",
      "epoch: 7, iter: 340, loss is: [2.4073126]\n",
      "epoch: 7, iter: 360, loss is: [2.4613376]\n",
      "epoch: 7, iter: 380, loss is: [2.5076485]\n",
      "epoch: 7, iter: 400, loss is: [2.4595442]\n",
      "epoch: 7, iter: 420, loss is: [2.4882753]\n",
      "epoch: 7, iter: 440, loss is: [2.449201]\n",
      "epoch: 7, iter: 460, loss is: [2.4233477]\n",
      "epoch: 7, iter: 480, loss is: [2.4480085]\n",
      "epoch: 7, iter: 500, loss is: [2.4489512]\n",
      "epoch: 7, iter: 520, loss is: [2.4165885]\n",
      "epoch: 8, iter: 0, loss is: [2.430614]\n",
      "epoch: 8, iter: 20, loss is: [2.4493961]\n",
      "epoch: 8, iter: 40, loss is: [2.519155]\n",
      "epoch: 8, iter: 60, loss is: [2.459505]\n",
      "epoch: 8, iter: 80, loss is: [2.4392848]\n",
      "epoch: 8, iter: 100, loss is: [2.4385705]\n",
      "epoch: 8, iter: 120, loss is: [2.4339323]\n",
      "epoch: 8, iter: 140, loss is: [2.4758897]\n",
      "epoch: 8, iter: 160, loss is: [2.4632874]\n",
      "epoch: 8, iter: 180, loss is: [2.4119601]\n",
      "epoch: 8, iter: 200, loss is: [2.426652]\n",
      "epoch: 8, iter: 220, loss is: [2.4374573]\n",
      "epoch: 8, iter: 240, loss is: [2.4416533]\n",
      "epoch: 8, iter: 260, loss is: [2.4302282]\n",
      "epoch: 8, iter: 280, loss is: [2.4083343]\n",
      "epoch: 8, iter: 300, loss is: [2.4982152]\n",
      "epoch: 8, iter: 320, loss is: [2.4408238]\n",
      "epoch: 8, iter: 340, loss is: [2.4101322]\n",
      "epoch: 8, iter: 360, loss is: [2.4278097]\n",
      "epoch: 8, iter: 380, loss is: [2.4271111]\n",
      "epoch: 8, iter: 400, loss is: [2.446088]\n",
      "epoch: 8, iter: 420, loss is: [2.4818325]\n",
      "epoch: 8, iter: 440, loss is: [2.5116353]\n",
      "epoch: 8, iter: 460, loss is: [2.4265606]\n",
      "epoch: 8, iter: 480, loss is: [2.423789]\n",
      "epoch: 8, iter: 500, loss is: [2.4944434]\n",
      "epoch: 8, iter: 520, loss is: [2.387095]\n",
      "epoch: 9, iter: 0, loss is: [2.4918723]\n",
      "epoch: 9, iter: 20, loss is: [2.481937]\n",
      "epoch: 9, iter: 40, loss is: [2.4212954]\n",
      "epoch: 9, iter: 60, loss is: [2.4932282]\n",
      "epoch: 9, iter: 80, loss is: [2.4060304]\n",
      "epoch: 9, iter: 100, loss is: [2.4208622]\n",
      "epoch: 9, iter: 120, loss is: [2.4344742]\n",
      "epoch: 9, iter: 140, loss is: [2.4069686]\n",
      "epoch: 9, iter: 160, loss is: [2.410719]\n",
      "epoch: 9, iter: 180, loss is: [2.4288006]\n",
      "epoch: 9, iter: 200, loss is: [2.4386642]\n",
      "epoch: 9, iter: 220, loss is: [2.4459195]\n",
      "epoch: 9, iter: 240, loss is: [2.4130907]\n",
      "epoch: 9, iter: 260, loss is: [2.446156]\n",
      "epoch: 9, iter: 280, loss is: [2.417375]\n",
      "epoch: 9, iter: 300, loss is: [2.431727]\n",
      "epoch: 9, iter: 320, loss is: [2.4960873]\n",
      "epoch: 9, iter: 340, loss is: [2.4034996]\n",
      "epoch: 9, iter: 360, loss is: [2.4358501]\n",
      "epoch: 9, iter: 380, loss is: [2.4514382]\n",
      "epoch: 9, iter: 400, loss is: [2.4122257]\n",
      "epoch: 9, iter: 420, loss is: [2.4507515]\n",
      "epoch: 9, iter: 440, loss is: [2.5006049]\n",
      "epoch: 9, iter: 460, loss is: [2.4409828]\n",
      "epoch: 9, iter: 480, loss is: [2.370307]\n",
      "epoch: 9, iter: 500, loss is: [2.4612007]\n",
      "epoch: 9, iter: 520, loss is: [2.42449]\n",
      "模型保存成功，模型参数保存在MLP_model中\n"
     ]
    }
   ],
   "source": [
    "# 模型训练和保存\n",
    "with dygraph.guard(fluid.CPUPlace()):\n",
    "    EPOCH_NUM = 10   # 设置外层循环次数\n",
    "    BATCH_SIZE = 4096  # 设置batch大小\n",
    "    \n",
    "    # 定义外层循环\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\n",
    "        np.random.shuffle(training_data)\n",
    "        # 将训练数据进行拆分\n",
    "        mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\n",
    "        \n",
    "        # 定义内层循环\n",
    "        for iter_id, mini_batch in enumerate(mini_batches):\n",
    "            x = np.array(mini_batch[:, :-1]).astype('float32') # 获得当前批次训练数据\n",
    "            y = np.array(mini_batch[:, -1:]).astype('float32') # 获得当前批次训练标签\n",
    "\n",
    "            # 将numpy数据转为飞桨动态图variable形式\n",
    "            buyer_features = dygraph.to_variable(x)\n",
    "            result = dygraph.to_variable(y)\n",
    "            \n",
    "            # 前向计算\n",
    "            predicts = model(buyer_features)\n",
    "            # loss = fluid.layers.log_loss(predicts, prices)\n",
    "            loss = wce_loss(predicts, result)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            # logloss = fluid.layers.log_loss(predicts, prices)\n",
    "\n",
    "            if iter_id % 20 == 0:\n",
    "                print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\n",
    "                # print(predicts)\n",
    "     \n",
    "            # 反向传播\n",
    "            avg_loss.backward()\n",
    "            # 最小化loss,更新参数\n",
    "            opt.minimize(avg_loss)\n",
    "            # 清除梯度\n",
    "            model.clear_gradients()\n",
    "    # 保存模型\n",
    "    fluid.save_dygraph(model.state_dict(), 'MLP_model')\n",
    "    print(\"模型保存成功，模型参数保存在MLP_model中\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result is [[0.65414643]\n",
      " [0.9220496 ]\n",
      " [0.9159751 ]\n",
      " [0.51936257]\n",
      " [0.55256414]]\n"
     ]
    }
   ],
   "source": [
    "with dygraph.guard():\n",
    "    # 参数为保存模型参数的文件地址\n",
    "    model_dict, _ = fluid.load_dygraph('MLP_model')\n",
    "    model.load_dict(model_dict)\n",
    "    model.eval()\n",
    "    pre = pre_data.astype('float32')\n",
    "    # 将数据转为动态图的variable格式\n",
    "    pre = dygraph.to_variable(pre)\n",
    "    results = model(pre)\n",
    "\n",
    "    print(\"Inference result is {}\".format(results.numpy()[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685471\n"
     ]
    }
   ],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65414643, 0.9220496 , 0.9159751 , 0.51936257, 0.55256414,\n",
       "       0.9197315 ], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.numpy().flatten()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('X_test.csv', usecols=['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(\n",
    "{    \"customer_id\": sub.customer_id, \n",
    "    \"pred\": results.numpy().flatten()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000014</td>\n",
       "      <td>0.654146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000034</td>\n",
       "      <td>0.922050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000046</td>\n",
       "      <td>0.915975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000069</td>\n",
       "      <td>0.519363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000105</td>\n",
       "      <td>0.552564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id      pred\n",
       "0      1000014  0.654146\n",
       "1      1000034  0.922050\n",
       "2      1000046  0.915975\n",
       "3      1000069  0.519363\n",
       "4      1000105  0.552564"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/data19383/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1585986 entries, 0 to 1585985\n",
      "Data columns (total 2 columns):\n",
      "customer_id    1585986 non-null int64\n",
      "result         1585986 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 24.2 MB\n"
     ]
    }
   ],
   "source": [
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.merge(sub, df_preds, on='customer_id', how='left')\n",
    "submission.fillna(0,inplace=True)\n",
    "submission = submission[['customer_id','pred']]\n",
    "submission.rename(columns={'customer_id':'customer_id','pred':'result'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000014</td>\n",
       "      <td>0.654146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000034</td>\n",
       "      <td>0.922050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000046</td>\n",
       "      <td>0.915975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id    result\n",
       "0      1000000  0.000000\n",
       "1      1000014  0.654146\n",
       "2      1000034  0.922050\n",
       "3      1000046  0.915975\n",
       "4      1000048  0.000000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将概率值转换为用户是否购买的标签\n",
    "def f(x):\n",
    "    if x <= 0.5:\n",
    "        return 0\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission['result'] = submission['result'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 写在最后\n",
    "\n",
    "### 可选优化方案\n",
    "\n",
    "> 本次比赛可调优空间非常大，可尝试且不限于从以下方面来进行调优，如果尝试后发现效果并不理想，可以在基线项目的评论区中和大家一起讨论~\n",
    "\n",
    "**数据处理**\n",
    "\n",
    "> 1. 归一化方案 - 直接拉伸是最佳方式吗？\n",
    "> 2. 离散值与连续值 - 哪种方式更适合处理这些方式？是否有较为通用的方法可以尝试？是否可以使用Embedding？\n",
    "> 3. 特征工程 - 除了时间滑窗是否可以有其它特征？有没有不使用特征工程的解决方案？\n",
    "> 4. 特征选择 - 输入特征真的是越多越好吗？如何选择特征以克服神经网络训练的不稳定性？\n",
    "> 5. 数据集划分比例 - 训练集、验证集、测试集应该怎样划分效果更好？\n",
    "\n",
    "**首层网络选择**\n",
    "\n",
    "> 1. Embedding还是Linear、Conv？- 如果使用卷积应该怎样处理shape？\n",
    "> 2. 多字段合并输入还是分开输入？- 分开输入效果一定好吗？哪些字段更适合合并输入？\n",
    "\n",
    "**网络(Backbone)部分搭建**\n",
    "\n",
    "> 1. 隐层大小选择 - 宽度和层数\n",
    "> 2. 尝试复杂网络构建 - 是否可以尝试简单CNN、RNN？如何使用飞桨复现经典解决方案？是否可以尝试使用图神经网络？如何使用PGL构建本赛题的异构图？\n",
    "> 3. 选择更合适的激活函数\n",
    "> 4. 尝试正则化、dropout等方式避免过拟合\n",
    "> 5. 尝试非Xavier初始化方案\n",
    "\n",
    "**模型(Model)搭建以及训练相关**\n",
    "\n",
    "> 1. 选择学习率等超参数\n",
    "> 2. 选择合适的损失函数 - 如何处理数据不平衡问题？\n",
    "> 3. 尝试不同的优化器\n",
    "> 4. 尝试使用学习率调度器\n",
    "> 5. 避免脏数据干扰(用深度学习的方式更优更方便)\n",
    "\n",
    "**模型融合**\n",
    "\n",
    "> 1. 深度学习模型自身是否需要进行模型融合？模型融合是否能克服神经网络训练的不稳定性？\n",
    "> 2. 是否能使用不同深度学习模型进行融合？\n",
    "\n",
    "**提交相关**\n",
    "\n",
    "> 1. 测试集表现最好的模型一定是最优秀的吗？\n",
    "> 2. 用准确率来衡量二分类模型的能力是最好选择吗？\n",
    "\n",
    "### 参考资料\n",
    "\n",
    "- 用户购买预测练习赛总结\n",
    "  - [用户购买预测练习赛：数据集探索分析（EDA）](https://aistudio.baidu.com/aistudio/projectdetail/438644)\n",
    "\n",
    "      - 介绍时间序列数据常见的探索思路在AI Studio上的实现\n",
    "\n",
    "  - [用户购买预测练习赛：时间滑窗特征构建](https://aistudio.baidu.com/aistudio/projectdetail/276829)\n",
    "\n",
    "      - 介绍时间序列数据上时间滑窗的特征的生成与内存优化策略\n",
    "\n",
    "  - [用户购买预测练习赛：用户和产品特征构建](https://aistudio.baidu.com/aistudio/projectdetail/438772)\n",
    "\n",
    "      - 介绍基本推荐算法的特征工程在比赛数据集上的实现\n",
    "\n",
    "  - [用户购买预测练习赛：月销量预测实现](https://aistudio.baidu.com/aistudio/projectdetail/438793)\n",
    "\n",
    "      - 另一种时间滑窗思路，按月预测销量，属于分支探索\n",
    "- [连锁超市销量预估案例](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)\n",
    "  - [数据集已上传到AI Studio平台](https://aistudio.baidu.com/aistudio/datasetdetail/17815)\n",
    "  - [第一名解决方案](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582)\n",
    "  - [第五名解决方案](https://github.com/LenzDu/Kaggle-Competition-Favorita)\n",
    "- [月销量预测案例](https://www.kaggle.com/c/competitive-data-science-predict-future-sales)\n",
    "- [一套系统的特征工程框架](https://github.com/dayeren/Kaggle_Competition_Treasure/tree/master/Recommendations/Instacart)\n",
    "\n",
    "## 代码审查\n",
    "\n",
    "如选手成绩靠前并收到官方邮件通知代码审查，请参考该[链接](https://aistudio.baidu.com/aistudio/projectdetail/743661)进行项目上传操作  \n",
    "快捷命令:`!zip -rP [此处添加审查邮件中的Key值] [邮件中的UID值].zip /home/aistudio/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
